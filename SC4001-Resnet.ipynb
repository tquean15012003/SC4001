{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f992dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchmetrics.classification import MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f21c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/queantran/opt/anaconda3/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/queantran/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'scale'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flowers102Classifier, plot_training_runs, get_train_val_test_loader, FineTuneType, TrainingRun\n",
      "File \u001b[0;32m~/Desktop/Harry/SC4001/utils_v2.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, random_split\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Define transforms for data augmentation and normalization\u001b[39;00m\n\u001b[1;32m     15\u001b[0m data_transforms_train \u001b[38;5;241m=\u001b[39m v2\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m     16\u001b[0m     [\n\u001b[1;32m     17\u001b[0m         v2\u001b[38;5;241m.\u001b[39mPILToTensor(),\n\u001b[1;32m     18\u001b[0m         v2\u001b[38;5;241m.\u001b[39mRandomResizedCrop(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m), antialias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     19\u001b[0m         v2\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m---> 20\u001b[0m         \u001b[43mv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToDtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# to float32 in [0, 1]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         v2\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m), std\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m)),  \u001b[38;5;66;03m# typically from ImageNe\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     ]    \n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m data_transforms_test \u001b[38;5;241m=\u001b[39m v2\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m     26\u001b[0m     [\n\u001b[1;32m     27\u001b[0m         v2\u001b[38;5;241m.\u001b[39mPILToTensor(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     ]\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     35\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'scale'"
     ]
    }
   ],
   "source": [
    "from utils_v2 import Flowers102Classifier, plot_training_runs, get_train_val_test_loader, FineTuneType, TrainingRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ff8f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SIZE: 816\n",
      "VALIDATION SIZE: 204\n",
      "TRAINING SIZE: 6149\n"
     ]
    }
   ],
   "source": [
    "train_loader, train_val_loader, validation_loader, test_loader = get_train_val_test_loader(mixup = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature extraction on a resnet18 backbone for 16 epochs.\n",
      "\n",
      "[1] Train Loss: 4.72572\n",
      "[1] Train Loss: 3.76083, Accuracy: 0.23197\n",
      "[1] Val Loss: 4.23376, Accuracy: 0.08185\n",
      "Current valdation accuracy 8.18 is better than previous best of 0.00. Saving checkpoint.\n",
      "[2] Train Loss: 3.49054\n",
      "[2] Train Loss: 2.72579, Accuracy: 0.67668\n",
      "[2] Val Loss: 3.38485, Accuracy: 0.42857\n",
      "Current valdation accuracy 42.86 is better than previous best of 8.18. Saving checkpoint.\n",
      "[3] Train Loss: 2.57728\n",
      "[3] Train Loss: 1.93658, Accuracy: 0.87139\n",
      "[3] Val Loss: 2.77192, Accuracy: 0.54762\n",
      "Current valdation accuracy 54.76 is better than previous best of 42.86. Saving checkpoint.\n",
      "[4] Train Loss: 1.93020\n",
      "[4] Train Loss: 1.38395, Accuracy: 0.94111\n",
      "[4] Val Loss: 2.32633, Accuracy: 0.63839\n",
      "Current valdation accuracy 63.84 is better than previous best of 54.76. Saving checkpoint.\n",
      "[5] Train Loss: 1.42808\n",
      "[5] Train Loss: 0.98940, Accuracy: 0.96635\n",
      "[5] Val Loss: 1.98740, Accuracy: 0.69792\n",
      "Current valdation accuracy 69.79 is better than previous best of 63.84. Saving checkpoint.\n",
      "[6] Train Loss: 1.09653\n",
      "[6] Train Loss: 0.75494, Accuracy: 0.97716\n",
      "[6] Val Loss: 1.81970, Accuracy: 0.69792\n",
      "[7] Train Loss: 0.87038\n",
      "[7] Train Loss: 0.69867, Accuracy: 0.98317\n",
      "[7] Val Loss: 1.72441, Accuracy: 0.72768\n",
      "Current valdation accuracy 72.77 is better than previous best of 69.79. Saving checkpoint.\n",
      "[8] Train Loss: 0.80324\n",
      "[8] Train Loss: 0.63090, Accuracy: 0.98798\n",
      "[8] Val Loss: 1.70947, Accuracy: 0.75000\n",
      "Current valdation accuracy 75.00 is better than previous best of 72.77. Saving checkpoint.\n",
      "[9] Train Loss: 0.74863\n",
      "[9] Train Loss: 0.59423, Accuracy: 0.98798\n",
      "[9] Val Loss: 1.64692, Accuracy: 0.73661\n",
      "[10] Train Loss: 0.70545\n",
      "[10] Train Loss: 0.54715, Accuracy: 0.99519\n",
      "[10] Val Loss: 1.62278, Accuracy: 0.74107\n",
      "[11] Train Loss: 0.64691\n",
      "[11] Train Loss: 0.52245, Accuracy: 0.99279\n",
      "[11] Val Loss: 1.61896, Accuracy: 0.74107\n",
      "[12] Train Loss: 0.61116\n",
      "[12] Train Loss: 0.48422, Accuracy: 0.99399\n",
      "[12] Val Loss: 1.54990, Accuracy: 0.75000\n",
      "[13] Train Loss: 0.56533\n",
      "[13] Train Loss: 0.45754, Accuracy: 0.99639\n",
      "[13] Val Loss: 1.52196, Accuracy: 0.73661\n",
      "[14] Train Loss: 0.56400\n",
      "[14] Train Loss: 0.45986, Accuracy: 0.99279\n",
      "[14] Val Loss: 1.52298, Accuracy: 0.75446\n",
      "Current valdation accuracy 75.45 is better than previous best of 75.00. Saving checkpoint.\n",
      "[15] Train Loss: 0.55343\n",
      "[15] Train Loss: 0.43327, Accuracy: 0.99639\n",
      "[15] Val Loss: 1.51357, Accuracy: 0.74554\n",
      "[16] Train Loss: 0.55155\n",
      "[16] Train Loss: 0.42902, Accuracy: 0.99399\n",
      "[16] Val Loss: 1.52728, Accuracy: 0.75446\n",
      "Done with feature extraction for resnet18-based model. Ran for 16 epochs.\n",
      "[resnet18] Best val accuracy after feature extraction is 0.7544642686843872\n",
      "\n",
      "Running fine-tuning for 8 epochs\n",
      "[1] Train Loss: 0.48288\n",
      "[1] Train Loss: 0.21041, Accuracy: 1.00000\n",
      "[1] Val Loss: 1.22337, Accuracy: 0.77530\n",
      "Current valdation accuracy 77.53 is better than previous best of 75.45. Saving checkpoint.\n",
      "[2] Train Loss: 0.27694\n",
      "[2] Train Loss: 0.13774, Accuracy: 0.99880\n",
      "[2] Val Loss: 1.13235, Accuracy: 0.77530\n",
      "[3] Train Loss: 0.18528\n"
     ]
    }
   ],
   "source": [
    "def transfer_learning_on_backbone(backbones, feature_extract_epochs, fine_tune_epochs):\n",
    "    \"\"\"Run transfer learning on multiple backbones for this classification task.\n",
    "    The choice of the backbone (pre-trained model) is a hyper-parameter.\n",
    "\n",
    "    We perform transfer-learning in 2 steps:\n",
    "    1. Feature extraction, which is run for feature_extract_epochs, and\n",
    "    2. Fine-tuning, which is run for fine_tune_epochs.\n",
    "\n",
    "    We save the model with the best validation accuracy after every epoch.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # Let's train the last classification later of the pre-trained model with the\n",
    "    # specified backbone on the Flowers 102 dataset.\n",
    "\n",
    "    training_runs = {}\n",
    "    for backbone in backbones:\n",
    "        best_cp_path = f'{backbone}_Flowers102_best.pt'\n",
    "        print(f\"Running feature extraction on a {backbone} backbone for {feature_extract_epochs} epochs.\\n\")\n",
    "        fc = Flowers102Classifier(backbone=backbone)\n",
    "        fc.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(fc.parameters())\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.3)\n",
    "        accuracy = MulticlassAccuracy(num_classes=102, average='micro').to(device)\n",
    "\n",
    "        # First freeze all the weights except for the newly added Linear layer.\n",
    "        fc.fine_tune(FineTuneType.NEW_LAYERS)\n",
    "\n",
    "        best_test_accuracy = 0.0\n",
    "        training_run = TrainingRun()\n",
    "        training_runs[backbone] = training_run\n",
    "\n",
    "        fc.train_multiple_epochs_and_save_best_checkpoint(\n",
    "            train_loader,\n",
    "            train_val_loader,\n",
    "            validation_loader,\n",
    "            accuracy,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            feature_extract_epochs,\n",
    "            best_cp_path,\n",
    "            training_run,\n",
    "        )\n",
    "\n",
    "        print(f\"Done with feature extraction for {backbone}-based model. Ran for {feature_extract_epochs} epochs.\")\n",
    "\n",
    "        best_val_accuracy = fc.get_metrics(\"val\")['accuracy']\n",
    "        print(f\"[{backbone}] Best val accuracy after feature extraction is {best_val_accuracy}\\n\")\n",
    "        print(f\"Running fine-tuning for {fine_tune_epochs} epochs\")\n",
    "\n",
    "        # Set all the parameters to be trainable.\n",
    "        fc.fine_tune(FineTuneType.ALL)\n",
    "\n",
    "        optimizer = torch.optim.Adam(fc.get_optimizer_params(), lr=1e-8)\n",
    "        # Every 2 steps reduce the LR to 70% of the previous value.\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.7)\n",
    "\n",
    "        fc.train_multiple_epochs_and_save_best_checkpoint(\n",
    "            train_loader,\n",
    "            train_val_loader,\n",
    "            validation_loader,\n",
    "            accuracy,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            fine_tune_epochs,\n",
    "            best_cp_path,\n",
    "            training_run,\n",
    "        )\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        print(f\"Accuracy of {backbone}-based pre-trained model with last layer replaced.\")\n",
    "        fc.eval()\n",
    "        fc.evaluate(test_loader, accuracy, 0, \"Val\")\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # end for (backbone)\n",
    "\n",
    "    # Now plot the training runs.\n",
    "    plot_training_runs(training_runs)\n",
    "\n",
    "\n",
    "# end def\n",
    "backbones = [\"resnet18\"]\n",
    "transfer_learning_on_backbone(backbones, feature_extract_epochs=16, fine_tune_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b2450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
